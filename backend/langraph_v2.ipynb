{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moperator\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ToolCall, ToolMessage\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StateGraph, END\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Define AgentState\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "from langchain_core.messages import ToolCall, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    " \n",
    "# Define AgentState\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    chat_history: list[BaseMessage]\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n",
    " \n",
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    " \n",
    "# Import tools\n",
    "from utils.tavily.core import web_search\n",
    "from utils.pytract.core import pytract_rag\n",
    " \n",
    "# Tool definitions\n",
    "@tool(\"web_search\")\n",
    "def web_tool(query: str, num_results: int = 5, score_threshold: float = 0.7):\n",
    "    return web_search(query, num_results, score_threshold)\n",
    " \n",
    "@tool(\"rag_search\")\n",
    "def rag_tool(search_params: list[dict], query: str, model: str) -> str:\n",
    "    nvidia_rag = pytract_rag()\n",
    "    return nvidia_rag.run_nvidia_text_generation_pipeline(search_params, query, model)\n",
    " \n",
    "@tool(\"snowflake_search\")\n",
    "def snowflake_tool(query: str, filters: dict = {}):\n",
    "    return \"hi from snowflake\"\n",
    " \n",
    "# Define tool mapping dictionary\n",
    "tool_str_to_func = {\n",
    "    \"web_search\": web_tool,\n",
    "    \"rag_search\": rag_tool,\n",
    "    \"snowflake_search\": snowflake_tool\n",
    "}\n",
    " \n",
    "# Scratchpad function to track intermediate steps\n",
    "def create_scratchpad(intermediate_steps: list[AgentAction]):\n",
    "    research_steps = []\n",
    "    for i, action in enumerate(intermediate_steps):\n",
    "        if action.log != \"TBD\":\n",
    "            research_steps.append(\n",
    "                f\"Tool: {action.tool}, input: {action.tool_input}\\n\"\n",
    "                f\"Output: {action.log}\"\n",
    "            )\n",
    "    return \"\\n---\\n\".join(research_steps)\n",
    " \n",
    "# Central Node (Oracle)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=0\n",
    ")\n",
    " \n",
    "def run_oracle(inputs):\n",
    "    return llm(inputs)\n",
    " \n",
    "def run_tool(inputs):\n",
    "    tool_name = inputs[\"tool\"]\n",
    "    return tool_str_to_func[tool_name].invoke(input=inputs[\"tool_input\"])\n",
    " \n",
    "graph = StateGraph(AgentState)\n",
    " \n",
    "graph.add_node(\"oracle\", run_oracle)\n",
    "graph.add_node(\"web_search\", run_tool)\n",
    "graph.add_node(\"rag_search\", run_tool)\n",
    "graph.add_node(\"snowflake_search\", run_tool)\n",
    "graph.add_node(\"generate_report\", run_tool)\n",
    " \n",
    "graph.set_entry_point(\"oracle\")\n",
    " \n",
    "# Create edges between nodes\n",
    "graph.add_edge(\"web_search\", \"oracle\")\n",
    "graph.add_edge(\"rag_search\", \"oracle\")\n",
    "graph.add_edge(\"snowflake_search\", \"oracle\")\n",
    "graph.add_edge(\"generate_report\", END)\n",
    " \n",
    "def generate_report(context):\n",
    "    return f\"Research Report:\\n\\nHistorical Performance:\\n{context['rag_search']}\\n\\nFinancial Metrics:\\n{context['snowflake_search']}\\n\\nIndustry Insights:\\n{context['web_search']}\"\n",
    " \n",
    "graph.add_node(\"generate_report\", generate_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
